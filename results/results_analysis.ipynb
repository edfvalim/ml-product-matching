{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd01d5d51aab73d9610ec47b9b307b85bba458be1808c0087ceef2f39693ec1d43d",
   "display_name": "Python 3.9.2 64-bit ('vis': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Results analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import t\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "source": [
    "Load metrics from results and save as single file."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_path = 'res_seed_42.csv'"
   ]
  },
  {
   "source": [
    "## Read results downloaded from the Google Colab\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_folder = os.path.join('..' , '..', 'results')\n",
    "# df = pd.DataFrame()\n",
    "# for root, subdirs, files in os.walk(results_folder):\n",
    "#     for f in files:\n",
    "#         if f == 'metrics.csv':\n",
    "#             d = pd.read_csv(os.path.join(root,f))\n",
    "#             if 'PL' in root:\n",
    "#                 d['lang'] = 'PL'\n",
    "#             elif 'ENG' in root:\n",
    "#                 d['lang'] = 'ENG'\n",
    "#             df = df.append(d)\n",
    "# df = df.drop(columns=['Unnamed: 0']).reset_index(drop=True)\n",
    "# df.to_csv(metrics_path, index=False)"
   ]
  },
  {
   "source": [
    "## Load files for analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_42 = pd.read_csv(metrics_path)\n",
    "df_42.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_size(r):\n",
    "    s = r[0]\n",
    "    lang = r[1]\n",
    "    if s == 'large' and lang == 'ENG':\n",
    "        return 15\n",
    "    elif s == 'large' and lang == 'PL':\n",
    "        return 7\n",
    "    elif s == 'medium':\n",
    "        return 3\n",
    "    else:\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_multiple = pd.read_csv('multiple_run.csv')\n",
    "df = df_multiple.append(df_42)\n",
    "df['size'] = df[['dataset_size', 'lang']].apply(encode_size, axis=1)\n",
    "experiment_ident = ['model','dataset_type','dataset_size', 'lang']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(experiment_ident).count()"
   ]
  },
  {
   "source": [
    "## Mean values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean = df.groupby(experiment_ident).mean()\n",
    "df_mean.round(4)"
   ]
  },
  {
   "source": [
    "## Standard Error"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "conf = 0.95\n",
    "t_correct = t.ppf((1+conf)/2, n-1)\n",
    "t_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std = df.groupby(experiment_ident).std()\n",
    "(df_std * t_correct).round(4)"
   ]
  },
  {
   "source": [
    "## Plots"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "sns.set_context(\"paper\", font_scale = 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df_mean.reset_index()\n",
    "metrics_df = d[['f1', 'precision', 'recall']].melt(ignore_index=False, var_name='metric')\n",
    "info_df = d[['model', 'size', 'dataset_size', 'dataset_type', 'lang']]\n",
    "metrics_info_df = metrics_df.merge(info_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_f1_prec_rec_for_model(data, model, model_label, bbox_anchor, xticksrot=0):\n",
    "    f = (data['model']==model) \n",
    "    d = data[f].sort_values(by='size', ascending=False)\n",
    "    g = sns.FacetGrid(d, col=\"metric\", hue='dataset_type', height=3.5)\n",
    "    g.map(sns.lineplot, 'size', 'value', legend=None, err_style=None)\n",
    "    g.map(sns.scatterplot, 'size', 'value')\n",
    "    g.set(xticks=data['size'].unique()[::-1])\n",
    "    g.set_xticklabels(['small', 'medium', 'large'], rotation=xticksrot)\n",
    "    ncol = data['dataset_type'].nunique()\n",
    "    g.add_legend(title='Dataset type', ncol=ncol,\n",
    "        loc='center', bbox_to_anchor=bbox_anchor,\n",
    "        markerscale=2.0)\n",
    "    plt.savefig(f'img/{model_label}_metrics.svg', bbox_inches = 'tight', pad_inches = 0)\n",
    "    plt.show()"
   ]
  },
  {
   "source": [
    "### Polish dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polish_df = metrics_info_df[metrics_info_df['lang'] == 'PL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f1_prec_rec_for_model(polish_df,'bert-base-multilingual-uncased', 'bert_PL', (0.41, -0.10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f1_prec_rec_for_model(polish_df, 'xlm-roberta-base', 'XLM-RoBERTa_PL', (0.41, -0.10))"
   ]
  },
  {
   "source": [
    "### English"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_df = metrics_info_df[metrics_info_df['lang'] == 'ENG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f1_prec_rec_for_model(english_df,'bert-base-multilingual-uncased', 'bert_ENG', (0.355, -0.15), xticksrot=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_f1_prec_rec_for_model(english_df, 'xlm-roberta-base', 'XLM-RoBERTa_ENG', (0.355, -0.15), xticksrot=45)"
   ]
  },
  {
   "source": [
    "## Dataset sizes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdc_sizes = pd.DataFrame([\n",
    "    {'dataset_type':'cameras',      'dataset_size':'small',     'n': 1886},\n",
    "    {'dataset_type':'cameras',      'dataset_size':'medium',    'n': 5255},\n",
    "    {'dataset_type':'cameras',      'dataset_size':'large',     'n': 20036},\n",
    "    {'dataset_type':'computers',    'dataset_size':'small',     'n': 2834},\n",
    "    {'dataset_type':'computers',    'dataset_size':'medium',    'n': 8094},\n",
    "    {'dataset_type':'computers',    'dataset_size':'large',     'n': 33359},\n",
    "    {'dataset_type':'watches',      'dataset_size':'small',     'n': 2255},\n",
    "    {'dataset_type':'watches',      'dataset_size':'medium',    'n': 6413},\n",
    "    {'dataset_type':'watches',      'dataset_size':'large',     'n': 27027},\n",
    "    {'dataset_type':'shoes',        'dataset_size':'small',     'n': 2063},\n",
    "    {'dataset_type':'shoes',        'dataset_size':'medium',    'n': 5805},\n",
    "    {'dataset_type':'shoes',        'dataset_size':'large',     'n': 22989},\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_f1_size(data, save):\n",
    "    sns.scatterplot(x='n', y='f1', hue='model', data=data, s=25)\n",
    "    plt.ylim(0.83,0.95)\n",
    "    plt.ylabel('F1 score')\n",
    "    plt.xlabel('Dataset size')\n",
    "    sns.despine()\n",
    "    plt.legend(title='Model',frameon=False, loc='center left', bbox_to_anchor=(1.02, 1))\n",
    "    plt.savefig(f'img/{save}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df[df['lang'] == 'ENG'].merge(wdc_sizes, on=['dataset_type', 'dataset_size'])\n",
    "plot_f1_size(d, 'f1_size_eng.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POLISH_DATASET_PATH = '../data/PolishDataset'\n",
    "types = ['all_train', 'chemia_train', 'napoje_train']\n",
    "sizes = []\n",
    "for t in types:\n",
    "    p = os.path.join(POLISH_DATASET_PATH, t)\n",
    "    for root, subdirs, files in os.walk(p):\n",
    "        for f in files:\n",
    "            data = pd.read_json(os.path.join(root, f), compression='gzip', lines=True)\n",
    "            name = f.replace('.json.gz', '').split('_')\n",
    "            sizes.append({\n",
    "                'dataset_type': name[2],\n",
    "                'dataset_size': name[3],\n",
    "                'n': len(data)\n",
    "            })\n",
    "sizes_pl_df = pd.DataFrame(sizes)\n",
    "sizes_pl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df[df['lang'] == 'PL'].merge(sizes_pl_df[~(sizes_pl_df['dataset_type'] == 'all')], on=['dataset_type', 'dataset_size'])\n",
    "plot_f1_size(d, 'f1_size_pl.svg')\n",
    "plt.show()\n"
   ]
  },
  {
   "source": [
    "## Fit time"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = df.merge(wdc_sizes, on=['dataset_type', 'dataset_size'])\n",
    "d2 = df.merge(sizes_pl_df, on=['dataset_type', 'dataset_size'])\n",
    "d = d1.append(d2)\n",
    "sns.regplot(x='n', y='time', data=d, x_estimator=np.mean, robust=True)\n",
    "plt.yticks([1800, 3600, 5400, 7200], labels=[30, 60, 90, 120])\n",
    "plt.ylabel('time [min]')\n",
    "plt.xlabel('dataset size')\n",
    "plt.savefig(f'img/fit_time.svg')"
   ]
  }
 ]
}